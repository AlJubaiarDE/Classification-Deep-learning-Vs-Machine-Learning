{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUA-GUDjrXDV",
        "colab_type": "text"
      },
      "source": [
        "# **Goal**\n",
        "Previously I created prediction model based on the deep learning keras libraries. In this part I want to create a prediction model based on the machine learning models and would like to observe the difference between the result. \n",
        "***I have already covered the Exploratory Data Analysis, Data Cleaning , Feature Engineering and much more on the deep learning part. So I skiped them in this section.*** Obiously, I cleaned the data properly for my model. But the overall details can be found on my deep learning part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7pNBHQZBSuI",
        "colab_type": "text"
      },
      "source": [
        "## **Train Test Split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_6nDk_IBZiu",
        "colab_type": "text"
      },
      "source": [
        "Import train_test_split from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvd4sEhxA5hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWislYo-BevX",
        "colab_type": "text"
      },
      "source": [
        "X is the feature variables\n",
        "\n",
        "y is the target variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUB6Fd2sBN3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= df.drop(\"loan_status\", axis = 1)\n",
        "y = df[\"loan_status\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKlkM0YvBiFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUyiTRz4BvWs",
        "colab_type": "text"
      },
      "source": [
        "## **Normalizing the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cwJUbGyB1M0",
        "colab_type": "text"
      },
      "source": [
        "Use MinMaxScaler to normalize the feature data X_train and X_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-tdCAx5B7Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkQO99CHCC5g",
        "colab_type": "text"
      },
      "source": [
        "We don't want data leakage from the test set so we only fitted on the X_train data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6yl_IoZCQbz",
        "colab_type": "text"
      },
      "source": [
        "# **Creating the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByV18Vu_Naps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression # to apply the Logistic regression\n",
        "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
        "from sklearn.model_selection import KFold # use for cross validation\n",
        "from sklearn.model_selection import GridSearchCV# for tuning parameter\n",
        "from sklearn.ensemble import RandomForestClassifier # for random forest classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm # for Support Vector Machine\n",
        "from sklearn import metrics # for the check the error and accuracy of the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5XrHiSaSCXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #lets Make a function for Grid Search CV\n",
        "def Classification_model_gridsearchCV(model,param_grid,X,y):\n",
        "    clf = GridSearchCV(model,param_grid,cv=10,scoring=\"accuracy\")\n",
        "    # this is how we use grid serch CV we are giving our model\n",
        "    # the we gave parameters those we want to tune\n",
        "    # Cv is for cross validation\n",
        "    # scoring means to score the classifier\n",
        "    \n",
        "    clf.fit(X_train,y_train)\n",
        "    print(\"The best parameter found on development set is :\")\n",
        "    # this will gie us our best parameter to use\n",
        "    print(clf.best_params_)\n",
        "    print(\"the bset estimator is \")\n",
        "    print(clf.best_estimator_)\n",
        "    print(\"The best score is \")\n",
        "    # this is the best score that we can achieve using these parameters#\n",
        "    print(clf.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvFhtDC7rWfL",
        "colab_type": "text"
      },
      "source": [
        "Decison tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nbF1Tl7rGwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "ebeba68a-f814-496a-fdfd-72b87410e74f"
      },
      "source": [
        "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
        "              'min_samples_split': [2,3,4,5,6,7,8,9,10], \n",
        "              'min_samples_leaf':[2,3,4,5,6,7,8,9,10] }\n",
        "model= DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "%Classification_model_gridsearchCV(model,param_grid,X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best parameter found on development set is :\n",
            "{'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 9}\n",
            "the bset estimator is \n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=10, min_samples_split=9,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "The best score is \n",
            "0.8643174094892929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9qGD4yk4Xhg",
        "colab_type": "text"
      },
      "source": [
        "Deep learning model gave us an accuracy of 89%. Here, The Decision Tree Classifier is giving us an accuracy of 86%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deXtWVfZRmDe",
        "colab_type": "text"
      },
      "source": [
        "KNeighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yitGtaxbsbCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KNeighborsClassifier()\n",
        "\n",
        "k_range = list(range(1, 30))\n",
        "leaf_size = list(range(1,30))\n",
        "weight_options = ['uniform', 'distance']\n",
        "param_grid = {'n_neighbors': k_range, 'leaf_size': leaf_size, 'weights': weight_options}\n",
        "Classification_model_gridsearchCV(model,param_grid,X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndd7iAoCSA6Z",
        "colab_type": "text"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQz83Cg8SFGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=svm.SVC()\n",
        "param_grid = [\n",
        "              {'C': [1, 10, 100, 1000], \n",
        "               'kernel': ['linear']\n",
        "              },\n",
        "              {'C': [1, 10, 100, 1000], \n",
        "               'gamma': [0.001, 0.0001], \n",
        "               'kernel': ['rbf']\n",
        "              },\n",
        " ]\n",
        "Classification_model_gridsearchCV(model,param_grid,X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPUiwo88SW9s",
        "colab_type": "text"
      },
      "source": [
        "RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiyrDtFNTYup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [200,500,1000],\n",
        "    'max_features': [.5,.7],\n",
        "    'bootstrap': [False, True],\n",
        "    'max_depth':[3,6]\n",
        "}\n",
        "Classification_model_gridsearchCV(model,param_grid,X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdEkfiahTmX3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybrQKTMZ5JVN",
        "colab_type": "text"
      },
      "source": [
        "**#NOTE: My machine was taking so much time(more than 7 hours) for the output. So, I couldn't finish the prediction. obiously, I will continue this part later. And keep the notebook updated.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9CT6jJD5p7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}